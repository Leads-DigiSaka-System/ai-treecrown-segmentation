{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24265,"status":"ok","timestamp":1766982449650,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"Sq3kEjEmpHA5","outputId":"b4d9a9f4-50ff-431a-9e2a-223108a6378c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.4)\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n","Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.241)\n","Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n","Requirement already satisfied: click!=8.2.*,\u003e=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n","Requirement already satisfied: cligj\u003e=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy\u003e=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n","Requirement already satisfied: pyogrio\u003e=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.12.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n","Requirement already satisfied: pandas\u003e=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n","Requirement already satisfied: pyproj\u003e=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n","Requirement already satisfied: shapely\u003e=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n","Requirement already satisfied: matplotlib\u003e=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python\u003e=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow\u003e=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml\u003e=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch\u003e=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n","Requirement already satisfied: torchvision\u003e=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n","Requirement already satisfied: psutil\u003e=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars\u003e=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Requirement already satisfied: ultralytics-thop\u003e=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (4.61.1)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.4.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=2.0.0-\u003egeopandas) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=2.0.0-\u003egeopandas) (2025.3)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.20.0)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.1.6)\n","Requirement already satisfied: fsspec\u003e=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2025.3.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.3.0-\u003eultralytics) (1.17.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=1.8.0-\u003eultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch\u003e=1.8.0-\u003eultralytics) (3.0.3)\n","Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-314abpr4\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-314abpr4\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.31)\n","Requirement already satisfied: numpy\u003c2.3.0,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: absl-py~=2.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.3.1)\n","Requirement already satisfied: sounddevice~=0.5 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n","Requirement already satisfied: flatbuffers~=25.9 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n","Requirement already satisfied: CFFI\u003e=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice~=0.5-\u003emediapipe) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI\u003e=1.0-\u003esounddevice~=0.5-\u003emediapipe) (2.23)\n"]}],"source":["!pip install rasterio geopandas ultralytics\n","!pip install git+https://github.com/facebookresearch/segment-anything.git\n","!pip install opencv-python mediapipe"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1766982506466,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"7FbNHtU7LMvp"},"outputs":[],"source":["import time\n","import torch\n","import rasterio\n","import numpy as np\n","import cv2\n","from tqdm import tqdm\n","from shapely.geometry import Point, Polygon, MultiPolygon\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Polygon as MPLPolygon\n","from matplotlib.collections import PatchCollection\n","import geopandas as gpd\n","import json\n","from segment_anything import sam_model_registry, SamPredictor"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":284,"status":"ok","timestamp":1766982510168,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"},"user_tz":-480},"id":"WVChExNzLKLR"},"outputs":[],"source":["start_cpu_time = time.process_time()\n","\n","\n","def apply_global_nms(detection_info, all_polygons, detection_masks, iou_threshold=0.3):\n","    \"\"\"\n","    Apply Non-Maximum Suppression across all detections to remove duplicates\n","    \"\"\"\n","    if len(detection_info) == 0:\n","        return detection_info, all_polygons, detection_masks\n","\n","    # Sort by confidence (highest first)\n","    indices = sorted(range(len(detection_info)),\n","                    key=lambda i: detection_info[i]['confidence'],\n","                    reverse=True)\n","\n","    keep = []\n","    removed = set()\n","\n","    for i in indices:\n","        if i in removed:\n","            continue\n","\n","        keep.append(i)\n","        poly_i = all_polygons[i]\n","\n","        # Check against remaining detections\n","        for j in indices:\n","            if j \u003c= i or j in removed:\n","                continue\n","\n","            poly_j = all_polygons[j]\n","\n","            try:\n","                # Calculate IoU\n","                intersection = poly_i.intersection(poly_j).area\n","                union = poly_i.union(poly_j).area\n","\n","                if union \u003e 0:\n","                    iou = intersection / union\n","                    if iou \u003e iou_threshold:\n","                        removed.add(j)\n","            except Exception as e:\n","                continue\n","\n","    # Filter to keep only non-duplicate detections\n","    detection_info_filtered = [detection_info[i] for i in keep]\n","    all_polygons_filtered = [all_polygons[i] for i in keep]\n","    detection_masks_filtered = [detection_masks[i] for i in keep]\n","\n","    print(f\"Global NMS: {len(detection_info)} -\u003e {len(detection_info_filtered)} detections\")\n","\n","    return detection_info_filtered, all_polygons_filtered, detection_masks_filtered\n","\n","\n","def detect_with_yolo(image_path, model, tile_size=640, overlap=128,\n","                     resolution=1.0, conf_threshold=0.20, iou_threshold=0.45,\n","                     max_det=1000, apply_nms=True, nms_iou=0.3):\n","    \"\"\"\n","    Detect objects using YOLO model and return bounding boxes\n","\n","    Returns:\n","        Tuple of (boxes_list, full_image, original_dims, transform, crs)\n","    \"\"\"\n","    boxes_list = []  # List of all bounding boxes with metadata\n","\n","    # Load image\n","    try:\n","        with rasterio.open(image_path) as src:\n","            original_width, original_height = src.width, src.height\n","            transform = src.transform\n","            crs = src.crs\n","\n","            print(f\"Original image size: {original_width}x{original_height}\")\n","\n","            # Read full image\n","            if src.count \u003e= 3:\n","                full_image = src.read([1, 2, 3])\n","                full_image = np.transpose(full_image, (1, 2, 0))\n","            else:\n","                full_image = src.read(1)\n","                if len(full_image.shape) == 2:\n","                    full_image = cv2.cvtColor(full_image, cv2.COLOR_GRAY2RGB)\n","\n","            full_image = np.clip(full_image, 0, 255).astype(np.uint8)\n","    except:\n","        print(\"Loading as regular image (not GeoTIFF)...\")\n","        full_image = cv2.imread(image_path)\n","        if full_image is None:\n","            raise ValueError(f\"Could not load image from {image_path}\")\n","\n","        full_image = cv2.cvtColor(full_image, cv2.COLOR_BGR2RGB)\n","        original_height, original_width = full_image.shape[:2]\n","\n","        print(f\"Original image size: {original_width}x{original_height}\")\n","\n","        from rasterio.transform import from_bounds\n","        transform = from_bounds(0, 0, original_width, original_height, original_width, original_height)\n","        crs = None\n","\n","    # Calculate scaled dimensions\n","    new_width = int(original_width * resolution)\n","    new_height = int(original_height * resolution)\n","    print(f\"Processing at: {new_width}x{new_height} (resolution={resolution})\")\n","\n","    resized_image = cv2.resize(full_image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n","\n","    # Create tiles\n","    tile_positions = []\n","    step_size = tile_size - overlap\n","\n","    for y in range(0, new_height, step_size):\n","        for x in range(0, new_width, step_size):\n","            x_end = min(x + tile_size, new_width)\n","            y_end = min(y + tile_size, new_height)\n","            tile_positions.append((x, y, x_end, y_end))\n","\n","    print(f\"Processing {len(tile_positions)} tiles with YOLO...\")\n","\n","    # Process tiles\n","    for x, y, x_end, y_end in tqdm(tile_positions, desc=\"YOLO Detection\"):\n","        win_w = x_end - x\n","        win_h = y_end - y\n","\n","        # Extract tile\n","        tile = resized_image[y:y_end, x:x_end]\n","\n","        if tile.shape[:2] != (tile_size, tile_size):\n","            tile = cv2.resize(tile, (tile_size, tile_size))\n","            scale_x = win_w / tile_size\n","            scale_y = win_h / tile_size\n","        else:\n","            scale_x = scale_y = 1.0\n","\n","        tile = np.ascontiguousarray(tile)\n","\n","        # Run YOLO detection\n","        results = model.predict(\n","            source=tile,\n","            conf=conf_threshold,\n","            iou=iou_threshold,\n","            max_det=max_det,\n","            save_txt=False,\n","            save_conf=True,\n","            verbose=False\n","        )\n","\n","        if results[0].boxes is not None and len(results[0].boxes) \u003e 0:\n","            boxes = results[0].boxes.xyxy.cpu().numpy()\n","            confidences = results[0].boxes.conf.cpu().numpy()\n","\n","            # Transform boxes to original image coordinates\n","            for i in range(len(boxes)):\n","                x1, y1, x2, y2 = boxes[i]\n","\n","                # Scale back to tile dimensions\n","                x1_scaled = x1 * scale_x\n","                y1_scaled = y1 * scale_y\n","                x2_scaled = x2 * scale_x\n","                y2_scaled = y2 * scale_y\n","\n","                # Transform to global scaled image coordinates\n","                x1_global = x1_scaled + x\n","                y1_global = y1_scaled + y\n","                x2_global = x2_scaled + x\n","                y2_global = y2_scaled + y\n","\n","                # Transform to original image coordinates\n","                x1_orig = int(x1_global / resolution)\n","                y1_orig = int(y1_global / resolution)\n","                x2_orig = int(x2_global / resolution)\n","                y2_orig = int(y2_global / resolution)\n","\n","                boxes_list.append({\n","                    'bbox': [x1_orig, y1_orig, x2_orig, y2_orig],\n","                    'confidence': float(confidences[i])\n","                })\n","\n","    print(f\"YOLO detected {len(boxes_list)} boxes before NMS\")\n","\n","    # Apply NMS to remove duplicates\n","    if apply_nms and len(boxes_list) \u003e 0:\n","        boxes_list = apply_nms_to_boxes(boxes_list, nms_iou)\n","        print(f\"After NMS: {len(boxes_list)} boxes\")\n","\n","    return boxes_list, full_image, (original_width, original_height), transform, crs\n","\n","\n","def apply_nms_to_boxes(boxes_list, iou_threshold=0.3):\n","    \"\"\"Apply NMS to bounding boxes\"\"\"\n","    if len(boxes_list) == 0:\n","        return boxes_list\n","\n","    # Sort by confidence\n","    boxes_list = sorted(boxes_list, key=lambda x: x['confidence'], reverse=True)\n","\n","    keep = []\n","    removed = set()\n","\n","    for i in range(len(boxes_list)):\n","        if i in removed:\n","            continue\n","\n","        keep.append(boxes_list[i])\n","        box_i = boxes_list[i]['bbox']\n","\n","        for j in range(i + 1, len(boxes_list)):\n","            if j in removed:\n","                continue\n","\n","            box_j = boxes_list[j]['bbox']\n","            iou = calculate_box_iou(box_i, box_j)\n","\n","            if iou \u003e iou_threshold:\n","                removed.add(j)\n","\n","    return keep\n","\n","\n","def calculate_box_iou(box1, box2):\n","    \"\"\"Calculate IoU between two boxes [x1, y1, x2, y2]\"\"\"\n","    x1_inter = max(box1[0], box2[0])\n","    y1_inter = max(box1[1], box2[1])\n","    x2_inter = min(box1[2], box2[2])\n","    y2_inter = min(box1[3], box2[3])\n","\n","    if x2_inter \u003c x1_inter or y2_inter \u003c y1_inter:\n","        return 0.0\n","\n","    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n","\n","    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","\n","    union_area = box1_area + box2_area - inter_area\n","\n","    return inter_area / union_area if union_area \u003e 0 else 0.0\n","\n","\n","def download_sam_checkpoint(model_type=\"vit_h\", save_dir=\".\"):\n","    \"\"\"\n","    Download SAM checkpoint if not exists\n","\n","    Args:\n","        model_type: 'vit_h', 'vit_l', or 'vit_b'\n","        save_dir: Directory to save checkpoint\n","\n","    Returns:\n","        Path to checkpoint file\n","    \"\"\"\n","    import os\n","    import urllib.request\n","\n","    checkpoints = {\n","        'vit_h': 'sam_vit_h_4b8939.pth',\n","        'vit_l': 'sam_vit_l_0b3195.pth',\n","        'vit_b': 'sam_vit_b_01ec64.pth'\n","    }\n","\n","    urls = {\n","        'vit_h': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth',\n","        'vit_l': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth',\n","        'vit_b': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth'\n","    }\n","\n","    checkpoint_name = checkpoints[model_type]\n","    checkpoint_path = os.path.join(save_dir, checkpoint_name)\n","\n","    if os.path.exists(checkpoint_path):\n","        print(f\"✓ SAM checkpoint found: {checkpoint_path}\")\n","        return checkpoint_path\n","\n","    print(f\"Downloading SAM {model_type} checkpoint (~2.4GB for vit_h)...\")\n","    print(f\"This may take several minutes...\")\n","\n","    url = urls[model_type]\n","\n","    def download_progress(block_num, block_size, total_size):\n","        downloaded = block_num * block_size\n","        percent = min(downloaded / total_size * 100, 100)\n","        print(f\"\\rDownloading: {percent:.1f}%\", end='')\n","\n","    try:\n","        urllib.request.urlretrieve(url, checkpoint_path, download_progress)\n","        print(f\"\\n✓ Downloaded successfully: {checkpoint_path}\")\n","        return checkpoint_path\n","    except Exception as e:\n","        print(f\"\\n❌ Download failed: {e}\")\n","        print(\"\\nManual download instructions:\")\n","        print(f\"1. Download from: {url}\")\n","        print(f\"2. Save to: {checkpoint_path}\")\n","        raise\n","\n","\n","def segment_with_sam(image, boxes_list, sam_checkpoint=None,\n","                     model_type=\"vit_h\", device=\"cuda\", checkpoint_dir=\".\"):\n","    \"\"\"\n","    Segment objects using SAM based on YOLO bounding boxes\n","\n","    Args:\n","        image: Full resolution image (H, W, 3)\n","        boxes_list: List of boxes from YOLO\n","        sam_checkpoint: Path to SAM checkpoint (if None, will download)\n","        model_type: SAM model type ('vit_h', 'vit_l', 'vit_b')\n","        device: 'cuda' or 'cpu'\n","        checkpoint_dir: Directory to save/load checkpoint\n","\n","    Returns:\n","        List of segmentation masks with metadata\n","    \"\"\"\n","    from segment_anything import sam_model_registry, SamPredictor\n","\n","    # Download checkpoint if not provided\n","    if sam_checkpoint is None:\n","        sam_checkpoint = download_sam_checkpoint(model_type, checkpoint_dir)\n","    elif not os.path.exists(sam_checkpoint):\n","        print(f\"Checkpoint not found at {sam_checkpoint}\")\n","        sam_checkpoint = download_sam_checkpoint(model_type, checkpoint_dir)\n","\n","    print(f\"\\nLoading SAM model ({model_type})...\")\n","\n","    # Check device\n","    if device == \"cuda\" and not torch.cuda.is_available():\n","        print(\"CUDA not available, using CPU\")\n","        device = \"cpu\"\n","\n","    # Load SAM\n","    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","    sam.to(device=device)\n","    predictor = SamPredictor(sam)\n","\n","    print(f\"Setting image for SAM...\")\n","    predictor.set_image(image)\n","\n","    segmentation_results = []\n","\n","    print(f\"Segmenting {len(boxes_list)} objects with SAM...\")\n","    for idx, box_info in enumerate(tqdm(boxes_list, desc=\"SAM Segmentation\")):\n","        bbox = box_info['bbox']\n","        confidence = box_info['confidence']\n","\n","        # Convert bbox to SAM format [x1, y1, x2, y2]\n","        input_box = np.array(bbox)\n","\n","        # Predict mask\n","        masks, scores, logits = predictor.predict(\n","            point_coords=None,\n","            point_labels=None,\n","            box=input_box[None, :],\n","            multimask_output=False,\n","        )\n","\n","        # Get the mask (first one since multimask_output=False)\n","        mask = masks[0]\n","\n","        # Convert mask to polygon coordinates\n","        mask_coords = mask_to_polygon(mask)\n","\n","        if mask_coords is not None and len(mask_coords) \u003e= 3:\n","            segmentation_results.append({\n","                'mask': mask,\n","                'coords': mask_coords,\n","                'bbox': bbox,\n","                'confidence': confidence,\n","                'sam_score': float(scores[0])\n","            })\n","\n","    print(f\"SAM segmentation complete: {len(segmentation_results)} masks generated\")\n","\n","    return segmentation_results\n","\n","\n","def mask_to_polygon(mask):\n","    \"\"\"Convert binary mask to polygon coordinates\"\"\"\n","    # Find contours\n","    contours, _ = cv2.findContours(\n","        mask.astype(np.uint8),\n","        cv2.RETR_EXTERNAL,\n","        cv2.CHAIN_APPROX_SIMPLE\n","    )\n","\n","    if len(contours) == 0:\n","        return None\n","\n","    # Get the largest contour\n","    contour = max(contours, key=cv2.contourArea)\n","\n","    # Simplify contour\n","    epsilon = 0.001 * cv2.arcLength(contour, True)\n","    approx = cv2.approxPolyDP(contour, epsilon, True)\n","\n","    # Convert to (N, 2) array\n","    coords = approx.reshape(-1, 2)\n","\n","    return coords\n","\n","\n","def create_geodataframe(segmentation_results, transform, crs):\n","    \"\"\"Create GeoDataFrame from segmentation results\"\"\"\n","    all_polygons = []\n","    detection_info = []\n","\n","    for idx, result in enumerate(segmentation_results):\n","        coords = result['coords']\n","\n","        # Calculate centroid and area\n","        centroid_x = coords[:, 0].mean()\n","        centroid_y = coords[:, 1].mean()\n","\n","        try:\n","            polygon_shapely = Polygon(coords)\n","            if not polygon_shapely.is_valid:\n","                polygon_shapely = polygon_shapely.buffer(0)\n","            area_pixels = polygon_shapely.area\n","        except:\n","            continue\n","\n","        # Transform to geographic coordinates\n","        geo_coords = []\n","        for px, py in coords:\n","            geo_x, geo_y = rasterio.transform.xy(transform, py, px)\n","            geo_coords.append((geo_x, geo_y))\n","\n","        try:\n","            geo_polygon = Polygon(geo_coords)\n","            if not geo_polygon.is_valid:\n","                geo_polygon = geo_polygon.buffer(0)\n","        except:\n","            continue\n","\n","        all_polygons.append(geo_polygon)\n","        detection_info.append({\n","            'centroid_x': centroid_x,\n","            'centroid_y': centroid_y,\n","            'area_pixels': area_pixels,\n","            'confidence': result['confidence'],\n","            'sam_score': result['sam_score'],\n","            'num_points': len(coords)\n","        })\n","\n","    # Create GeoDataFrame\n","    gdf = gpd.GeoDataFrame({\n","        'geometry': all_polygons,\n","        'area_pixels': [d['area_pixels'] for d in detection_info],\n","        'confidence': [d['confidence'] for d in detection_info],\n","        'sam_score': [d['sam_score'] for d in detection_info],\n","        'centroid_x': [d['centroid_x'] for d in detection_info],\n","        'centroid_y': [d['centroid_y'] for d in detection_info],\n","        'num_points': [d['num_points'] for d in detection_info]\n","    }, crs=crs)\n","\n","    return gdf, detection_info\n","\n","\n","def visualize_results(image, segmentation_results, output_dir):\n","    \"\"\"Create visualization of segmentation results\"\"\"\n","    height, width = image.shape[:2]\n","\n","    fig, ax = plt.subplots(1, 1, figsize=(16, 12))\n","\n","    ax.imshow(image)\n","    ax.set_title(f'YOLO + SAM Segmentation Results - {len(segmentation_results)} Trees Detected',\n","                 fontsize=16, fontweight='bold')\n","    ax.set_axis_off()\n","\n","    if segmentation_results:\n","        for result in segmentation_results:\n","            coords = result['coords']\n","            coords_closed = np.vstack([coords, coords[0]])\n","\n","            # Draw outline\n","            ax.plot(coords_closed[:, 0], coords_closed[:, 1],\n","                   'lime', linewidth=2, alpha=0.8)\n","\n","            # Fill polygon\n","            polygon = MPLPolygon(coords, closed=True,\n","                               facecolor='lime', alpha=0.3,\n","                               edgecolor='lime', linewidth=2)\n","            ax.add_patch(polygon)\n","\n","    # Add statistics\n","    if segmentation_results:\n","        avg_conf = np.mean([r['confidence'] for r in segmentation_results])\n","        avg_sam = np.mean([r['sam_score'] for r in segmentation_results])\n","\n","        stats_text = (f\"Total Trees: {len(segmentation_results)}\\n\"\n","                     f\"Avg YOLO Conf: {avg_conf:.3f}\\n\"\n","                     f\"Avg SAM Score: {avg_sam:.3f}\")\n","\n","        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n","               fontsize=14, verticalalignment='top',\n","               bbox=dict(boxstyle=\"round\", fc=\"white\", alpha=0.9, pad=0.5))\n","\n","    ax.set_xlim(0, width)\n","    ax.set_ylim(height, 0)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{output_dir}/yolo_sam_segmentation.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","    plt.close()\n","\n","    print(f\"✓ Visualization saved to {output_dir}/yolo_sam_segmentation.png\")\n","\n","\n","def save_results(gdf, detection_info, output_dir, image_name):\n","    \"\"\"Save results to files\"\"\"\n","    if len(gdf) == 0:\n","        print(\"No detections to save\")\n","        return\n","\n","    # Save GeoJSON\n","    if gdf.crs is not None:\n","        geojson_path = f'{output_dir}/{image_name}_yolo_sam.geojson'\n","        gdf.to_file(geojson_path, driver='GeoJSON')\n","        print(f\"✓ Saved GeoJSON to {geojson_path}\")\n","    else:\n","        print(\"⚠ Skipping GeoJSON (no CRS)\")\n","\n","    # Save CSV\n","    csv_path = f'{output_dir}/{image_name}_yolo_sam.csv'\n","    gdf.drop(columns='geometry').to_csv(csv_path, index=False)\n","    print(f\"✓ Saved CSV to {csv_path}\")\n","\n","    # Save statistics\n","    stats = {\n","        'total_detections': len(gdf),\n","        'average_area': float(np.mean([d['area_pixels'] for d in detection_info])),\n","        'median_area': float(np.median([d['area_pixels'] for d in detection_info])),\n","        'average_yolo_confidence': float(np.mean([d['confidence'] for d in detection_info])),\n","        'average_sam_score': float(np.mean([d['sam_score'] for d in detection_info]))\n","    }\n","\n","    stats_path = f'{output_dir}/{image_name}_statistics.json'\n","    with open(stats_path, 'w') as f:\n","        json.dump(stats, f, indent=2)\n","    print(f\"✓ Saved statistics to {stats_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1B_K3iIb954LM5TXV7G4kBuEzYtHXlPCo"},"id":"aY0GzILpL8Le","outputId":"fa2675b6-1342-4a4f-a7c3-dc1ff5108d11"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    from ultralytics import YOLO\n","    import os\n","\n","    # Configuration\n","    IMAGE_PATH = \"/content/drive/MyDrive/AGRI/TreeCrown_Segmentation/DJI_0245.JPG\"\n","    YOLO_MODEL_PATH = \"/content/drive/MyDrive/AGRI/Tree_Detection/models/yolo11n-100epoch.pt\"\n","    OUTPUT_DIR = \"/content/drive/MyDrive/AGRI/TreeCrown_Segmentation\"\n","    SAM_MODEL_TYPE = \"vit_b\"  # Options: 'vit_h' (best), 'vit_l' (medium), 'vit_b' (fast)\n","\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","    print(\"=\"*60)\n","    print(\"YOLO DETECTION + SAM SEGMENTATION PIPELINE\")\n","    print(\"=\"*60)\n","\n","    # Step 1: YOLO Detection\n","    print(\"\\n[Step 1/3] Loading YOLO model and detecting objects...\")\n","    yolo_model = YOLO(YOLO_MODEL_PATH)\n","\n","    boxes_list, full_image, image_dims, transform, crs = detect_with_yolo(\n","        image_path=IMAGE_PATH,\n","        model=yolo_model,\n","        tile_size=1280,\n","        overlap=0,\n","        resolution=0.50,\n","        conf_threshold=0.10,\n","        iou_threshold=0.45,\n","        max_det=1000,\n","        apply_nms=True,\n","        nms_iou=0.3\n","    )\n","\n","    if len(boxes_list) == 0:\n","        print(\"❌ No objects detected by YOLO. Exiting.\")\n","        exit()\n","\n","    # Step 2: SAM Segmentation\n","    print(f\"\\n[Step 2/3] Segmenting {len(boxes_list)} objects with SAM...\")\n","    segmentation_results = segment_with_sam(\n","        image=full_image,\n","        boxes_list=boxes_list,\n","        sam_checkpoint=None,  # Will auto-download\n","        model_type=SAM_MODEL_TYPE,\n","        device=\"cuda\",\n","        checkpoint_dir=OUTPUT_DIR\n","    )\n","\n","    # Step 3: Save and Visualize\n","    print(\"\\n[Step 3/3] Creating outputs...\")\n","\n","    # Create GeoDataFrame\n","    gdf, detection_info = create_geodataframe(segmentation_results, transform, crs)\n","\n","    # Visualize\n","    visualize_results(full_image, segmentation_results, OUTPUT_DIR)\n","\n","    # Save results\n","    image_name = os.path.splitext(os.path.basename(IMAGE_PATH))[0]\n","    save_results(gdf, detection_info, OUTPUT_DIR, image_name)\n","\n","    end_cpu_time = time.process_time()\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"✓ COMPLETED\")\n","    print(f\"✓ Total detections: {len(segmentation_results)} trees\")\n","    print(f\"✓ Processing time: {end_cpu_time - start_cpu_time:.2f} seconds\")\n","    print(\"=\"*60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ul7V9xPwMyf7"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP2hhJKeJWHY6wCPWREKrl5","mount_file_id":"1v6B5hf3r7CLd6C1YM5jx42aQ_Wl5Z9a7","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}